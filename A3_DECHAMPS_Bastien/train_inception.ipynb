{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from train import train_model\n",
    "from inception import *\n",
    "from data import *\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import PIL.Image as Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'bird_dataset'\n",
    "batch_size = 32\n",
    "epochs = 25\n",
    "lr = 0.045\n",
    "momentum = 0.9\n",
    "seed = 44876\n",
    "save_dir = 'experiment'\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    'train': torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(data_dir + '/train_images/',\n",
    "                         transform=inceptionv3_train_transforms),\n",
    "    batch_size=batch_size, shuffle=True, num_workers=4),\n",
    "\n",
    "    'val': torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(data_dir + '/val_images/',\n",
    "                         transform=inceptionv3_test_transforms),\n",
    "    batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Inception3(num_classes=1000, aux_logits=True)\n",
    "state_dict = torch.load('experiment/iNat_2018_InceptionV3.pth.tar')['state_dict']\n",
    "model.load_state_dict(state_dict)    \n",
    "\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, 20)\n",
    "model.aux_logits = False\n",
    "\n",
    "for child, layer in model.named_children():\n",
    "    if child != 'fc':\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "if use_cuda:\n",
    "    print('Using GPU')\n",
    "    model.cuda()\n",
    "else:\n",
    "    print('Using CPU')\n",
    "    \n",
    "\n",
    "optimizer = optim.RMSprop(\n",
    "    model.parameters(),\n",
    "    lr=lr, \n",
    "    alpha=0.9, \n",
    "    eps=1.0, \n",
    "    weight_decay=0.00005\n",
    ")\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, 2, 0.94)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for 5 epoch the last layer\n",
    "model, _ = train_model(model, dataloaders, criterion, optimizer, exp_lr_scheduler, 5, False)\n",
    "\n",
    "# Unfreeze the whole network\n",
    "for child, layer in model.named_children():\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = True\n",
    "        \n",
    "optimizer = optim.RMSprop(\n",
    "    model.parameters(),\n",
    "    lr=0.045, \n",
    "    alpha=0.9, \n",
    "    eps=1.0, \n",
    "    weight_decay=0.00005\n",
    ")\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, 2, 0.94)\n",
    "\n",
    "# Train for 10 epochs the whole network\n",
    "model, _ = train_model(model, dataloaders, criterion, optimizer, exp_lr_scheduler, 10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), save_dir + '/inceptionv3_1_09417.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Inception3(num_classes=1000, aux_logits=True)\n",
    "state_dict = torch.load('experiment/iNat_2018_InceptionV3.pth.tar')['state_dict']\n",
    "model.load_state_dict(state_dict)    \n",
    "\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, 20)\n",
    "model.aux_logits = False\n",
    "\n",
    "model.load_state_dict(torch.load('experiment/inceptionv3_0.9417toretrain.pth'))\n",
    "\n",
    "model.cuda()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the whole network\n",
    "for child, layer in model.named_children():\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "optimizer = optim.RMSprop(\n",
    "    model.parameters(),\n",
    "    lr=0.001, \n",
    "    alpha=0.9, \n",
    "    eps=1.0, \n",
    "    weight_decay=0.0001\n",
    ")\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, 2, 0.7)\n",
    "\n",
    "# Train for 10 epochs the whole network\n",
    "model, val = train_model(model, dataloaders, criterion, optimizer, exp_lr_scheduler, 1, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
